{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.google.com/search?q=elon+musk\n",
      "https://en.wikipedia.org/wiki/Elon_Musk\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Input search term\n",
    "search = input(\"Enter keyword to be searched: \")\n",
    "str_concat = \"+\".join(search.split(\" \"))\n",
    "search_url = f\"https://www.google.com/search?q={str_concat}\"\n",
    "print(search_url)\n",
    "\n",
    "# Get the Google search results page\n",
    "google_page = rq.get(search_url)\n",
    "\n",
    "# Parse the page with BeautifulSoup\n",
    "google_soup = BeautifulSoup(google_page.text, \"html.parser\")\n",
    "\n",
    "# Find the Wikipedia link\n",
    "wiki_link = None\n",
    "for link in google_soup.find_all(\"a\"):\n",
    "    href = link.get(\"href\")\n",
    "    if \"wikipedia.org\" in href:\n",
    "        wiki_link = href\n",
    "        break\n",
    "wiki_link = wiki_link[7:]\n",
    "wiki_link = (wiki_link.split(\"&\"))[0]\n",
    "print(wiki_link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up link for getting page\n",
    "link = wiki_link\n",
    "\n",
    "headers = {                                                        #setting header for request\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"\n",
    "}\n",
    "\n",
    "html = rq.get(link , headers=headers, timeout= 20)\n",
    "\n",
    "soup = BeautifulSoup(html.text , \"html.parser\")                    #creating soup for the scrapping \n",
    "\n",
    "# print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "heading = soup.h1.text                                             #retrieve heading of the article\n",
    "paragraph=\"\"\n",
    "\n",
    "for sp in soup.find_all(\"p\"):\n",
    "    paragraph+=sp.text\n",
    "    # paragraph+=\"\\n\"\n",
    "\n",
    "paragraph = paragraph.strip()                                      #removing extra whitespaces from the paragraph\n",
    "# print(paragraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets remove all the citations from the file\n",
    "new_para=\"\"\n",
    "idx = 0\n",
    "while idx < len(paragraph):\n",
    "    if paragraph[idx] == \"[\":\n",
    "        # Skip everything until the closing bracket is found\n",
    "        while idx < len(paragraph) and paragraph[idx] != \"]\":\n",
    "            idx += 1\n",
    "        # Skip the closing bracket as well\n",
    "        idx += 1\n",
    "    else:\n",
    "        new_para += paragraph[idx]\n",
    "        idx += 1\n",
    "\n",
    "# print(new_para)\n",
    "paragraph = new_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = open(f\"{heading}.txt\",'w')\n",
    "fh.write(paragraph)\n",
    "fh.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
